{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T19:42:48.605023Z",
     "iopub.status.busy": "2025-07-28T19:42:48.604400Z",
     "iopub.status.idle": "2025-07-28T19:42:55.398222Z",
     "shell.execute_reply": "2025-07-28T19:42:55.396970Z",
     "shell.execute_reply.started": "2025-07-28T19:42:48.604997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets transformers librosa jiwer --quiet\n",
    "!pip install evaluate --quiet\n",
    "# dataset is used to handle and preprocess dataset\n",
    "# transformers is needed to run whisper\n",
    "# librosa for audio analysis\n",
    "# jiwer and evaluate for cer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T22:10:10.695342Z",
     "iopub.status.busy": "2025-07-28T22:10:10.695055Z",
     "iopub.status.idle": "2025-07-28T22:10:10.700941Z",
     "shell.execute_reply": "2025-07-28T22:10:10.700068Z",
     "shell.execute_reply.started": "2025-07-28T22:10:10.695307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import evaluate\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Define the base path for the Kaggle input data\n",
    "KAGGLE_INPUT_DIR = \"./data\"\n",
    "TRAIN_CSV_PATH = os.path.join(KAGGLE_INPUT_DIR, \"train.csv\")\n",
    "TEST_CSV_PATH = os.path.join(KAGGLE_INPUT_DIR, \"test.csv\")\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(KAGGLE_INPUT_DIR, \"sample.csv\")\n",
    "\n",
    "# Define paths for audio directories\n",
    "TRAIN_AUDIO_DIR = KAGGLE_INPUT_DIR\n",
    "TEST_AUDIO_DIR = KAGGLE_INPUT_DIR\n",
    "\n",
    "# Model checkpoint to use\n",
    "MODEL_CHECKPOINT = \"openai/whisper-small\"\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "SAVE_STEPS = 1000\n",
    "EVAL_STEPS = 1000\n",
    "LOGGING_STEPS = 500\n",
    "OUTPUT_DIR = \"./whisper-uyghur-asr\" # Directory to save model checkpoints and logs\n",
    "FP16 = torch.cuda.is_available()\n",
    "MAX_DURATION_IN_SECONDS = 30 # Max audio duration to filter out very long samples\n",
    "TRAIN_DATA_SUBSET_RATIO = 0.5 # parameter to use a subset of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. Data Loading and Preprocessing ---\n",
    "\n",
    "print(\"Loading dataframes...\")\n",
    "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "sample_submission_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "\n",
    "# Construct full file paths for audio\n",
    "train_df[\"filepath\"] = train_df[\"filepath\"].apply(lambda x: os.path.join(TRAIN_AUDIO_DIR, x))\n",
    "test_df[\"filepath\"] = test_df[\"filepath\"].apply(lambda x: os.path.join(TEST_AUDIO_DIR, x))\n",
    "\n",
    "# Sample a subset of the training data\n",
    "if TRAIN_DATA_SUBSET_RATIO < 1.0:\n",
    "    print(f\"Sampling {TRAIN_DATA_SUBSET_RATIO*100}% of the training data...\")\n",
    "    train_df = train_df.sample(frac=TRAIN_DATA_SUBSET_RATIO, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train samples (after sampling): {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# Create Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df).cast_column(\"filepath\", Audio(sampling_rate=16000))\n",
    "test_dataset = Dataset.from_pandas(test_df).cast_column(\"filepath\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 2. Initialize Processor and Model ---\n",
    "\n",
    "print(f\"Loading Whisper processor and model: {MODEL_CHECKPOINT}\")\n",
    "# Initialize WhisperProcessor\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 3. Prepare Data for Training ---\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    \"\"\"\n",
    "    Function to preprocess each batch of the dataset.\n",
    "    It loads audio, extracts features, and tokenizes transcriptions.\n",
    "    \"\"\"\n",
    "    # Load and resample audio data to 16kHz\n",
    "    audio = batch[\"filepath\"]\n",
    "    # Compute log-Mel spectrograms from the audio input\n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # Encode target text to label IDs\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"transcription\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "# Apply the preprocessing function to the datasets\n",
    "print(\"Preprocessing training dataset...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=train_dataset.column_names, # Remove original columns to keep only 'input_features' and 'labels'\n",
    "    num_proc=1 # Setting num_proc to 1 to disable multiprocessing\n",
    ")\n",
    "\n",
    "print(\"Preprocessing test dataset (only input features needed for inference)...\")\n",
    "# For the test set, we only need input features, no labels\n",
    "test_dataset_processed = test_dataset.map(\n",
    "    lambda batch: {\"input_features\": processor.feature_extractor(batch[\"filepath\"][\"array\"], sampling_rate=batch[\"filepath\"][\"sampling_rate\"]).input_features[0]},\n",
    "    remove_columns=test_dataset.column_names,\n",
    "    num_proc=1 # Setting num_proc to 1 to disable multiprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 4. Define Data Collator ---\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received,\n",
    "    and also collate them into a batch.\n",
    "    \"\"\"\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # Split inputs and labels\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # Get the input_ids and pad them\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # Replace padding with -100 to ignore it in the loss calculation\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # If bos token is appended in previous step,\n",
    "        # cut it here as it's not needed for training\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 5. Define Metrics ---\n",
    "\n",
    "print(\"Loading CER metric...\")\n",
    "metric = evaluate.load(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Function to compute Character Error Rate (CER) during evaluation.\n",
    "    \"\"\"\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # Decode predictions and labels\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Compute CER\n",
    "    cer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 6. Set up Training Arguments ---\n",
    "\n",
    "print(\"Setting up training arguments...\")\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_steps=500, # Number of steps for linear warmup\n",
    "    max_steps=NUM_TRAIN_EPOCHS * (len(train_dataset) // BATCH_SIZE),\n",
    "    # num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    predict_with_generate=True, # Generate predictions during evaluation\n",
    "    fp16=FP16, # Use mixed precision if GPU is available\n",
    "    push_to_hub=False, # Do not push to Hugging Face Hub\n",
    "    load_best_model_at_end=True, # Load the best model based on evaluation metric\n",
    "    metric_for_best_model=\"cer\", # Metric to monitor for best model selection\n",
    "    greater_is_better=False, # For CER, lower is better\n",
    "    save_steps=SAVE_STEPS,\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    report_to=[\"tensorboard\"], # Report logs to TensorBoard\n",
    "    do_eval=True,\n",
    ")\n",
    "\n",
    "# Split train_dataset into train and validation for evaluation during training\n",
    "# Using a fixed seed for reproducibility\n",
    "train_test_split = train_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset_split = train_test_split[\"train\"]\n",
    "eval_dataset_split = train_test_split[\"test\"]\n",
    "\n",
    "print(f\"Training dataset size (after split): {len(train_dataset_split)}\")\n",
    "print(f\"Validation dataset size: {len(eval_dataset_split)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T19:43:42.611443Z",
     "iopub.status.busy": "2025-07-28T19:43:42.610573Z",
     "iopub.status.idle": "2025-07-28T19:45:19.803716Z",
     "shell.execute_reply": "2025-07-28T19:45:19.803091Z",
     "shell.execute_reply.started": "2025-07-28T19:43:42.611410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframes...\n",
      "Sampling 50.0% of the training data...\n",
      "Train samples (after sampling): 3787\n",
      "Test samples: 1894\n",
      "Loading Whisper processor and model: openai/whisper-small\n",
      "Preprocessing training dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696cabd3057b4793a5af09f40e550072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3787 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing test dataset (only input features needed for inference)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb69a202f06e4c689ae54131852e62f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1894 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CER metric...\n",
      "Setting up training arguments...\n",
      "Training dataset size (after split): 3408\n",
      "Validation dataset size: 379\n",
      "Initializing Trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8604/2391983317.py:208: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Initialize Trainer and Train Model ---\n",
    "\n",
    "print(\"Initializing Trainer...\")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_split,\n",
    "    eval_dataset=eval_dataset_split,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor\n",
    ")\n",
    "\n",
    "\n",
    "# Commented the following code as kernel crashed midway. Restarted training after picking up from checkpoint.\n",
    "# print(\"Starting training...\")\n",
    "# trainer.train()\n",
    "\n",
    "# print(\"Training complete! Saving final model...\")\n",
    "# trainer.save_model(os.path.join(OUTPUT_DIR, \"final_model\"))\n",
    "# processor.save_pretrained(os.path.join(OUTPUT_DIR, \"final_processor\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T19:45:56.635498Z",
     "iopub.status.busy": "2025-07-28T19:45:56.635159Z",
     "iopub.status.idle": "2025-07-28T21:23:03.247557Z",
     "shell.execute_reply": "2025-07-28T21:23:03.246542Z",
     "shell.execute_reply.started": "2025-07-28T19:45:56.635476Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from checkpoint in: /kaggle/working/whisper-uyghur-asr/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1893' max='1893' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1893/1893 1:36:56, Epoch 8/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/kaggle/working/whisper-uyghur-asr/checkpoint-1000\"\n",
    "\n",
    "# Check if the checkpoint directory exists before attempting to resume\n",
    "if os.path.exists(checkpoint_path) and os.listdir(checkpoint_path):\n",
    "    print(f\"Resuming training from checkpoint in: {checkpoint_path}\")\n",
    "    trainer.train(resume_from_checkpoint=checkpoint_path)\n",
    "else:\n",
    "    print(\"No valid checkpoint found. Starting training from scratch.\")\n",
    "    trainer.train()\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:24:29.021149Z",
     "iopub.status.busy": "2025-07-28T21:24:29.020804Z",
     "iopub.status.idle": "2025-07-28T21:51:50.194108Z",
     "shell.execute_reply": "2025-07-28T21:51:50.193328Z",
     "shell.execute_reply.started": "2025-07-28T21:24:29.021124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1894 transcriptions for the test set.\n",
      "Creating submission file...\n",
      "Submission file saved to submission.csv\n",
      "Script finished successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Inference on Test Data ---\n",
    "\n",
    "print(\"Performing inference on test data...\")\n",
    "\n",
    "predictions = []\n",
    "# Iterate through the test dataset in batches for efficient inference\n",
    "for i in range(0, len(test_dataset_processed), BATCH_SIZE):\n",
    "    batch = test_dataset_processed[i : i + BATCH_SIZE]\n",
    "    input_features = torch.tensor(batch[\"input_features\"]).to(model.device)\n",
    "\n",
    "    # Generate predictions\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features)\n",
    "\n",
    "    # Decode predictions\n",
    "    transcriptions = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    predictions.extend(transcriptions)\n",
    "\n",
    "print(f\"Generated {len(predictions)} transcriptions for the test set.\")\n",
    "\n",
    "# --- 9. Create Submission File ---\n",
    "\n",
    "print(\"Creating submission file...\")\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": test_df[\"ID\"],\n",
    "    \"transcription\": predictions\n",
    "})\n",
    "\n",
    "submission_path = \"submission.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved to {submission_path}\")\n",
    "print(\"Script finished successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13172482,
     "sourceId": 108756,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
